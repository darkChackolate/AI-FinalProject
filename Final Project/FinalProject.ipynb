{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement two classification algorithms for detecting faces and classifying digits:\n",
    "(a) Perceptron\n",
    "(b) Two-layer Neural Network (input layer, one hidden layer, output)\n",
    "2. Design the features for each of the two problems, and write a program for extracting the features from each image.\n",
    "You can also use the raw pixels directly as features (and avoid the process of designing features altogether) if that\n",
    "results in a better classification accuracy.\n",
    "3. Train the two algorithms on the part of the data set that is reserved for training. First, use only 10% of the data points\n",
    "that are reserved for training, then 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and finally 100%. All the results\n",
    "should a function of the number of data points used for training.\n",
    "4. Compare the performances of the two algorithms using the part of the data set that is reserved for testing, and report:\n",
    "• The time needed for training as a function of the number of data points used for training.\n",
    "• The prediction error (and standard deviation) as a function of the number of data points used for training.\n",
    "5. Write a report describing the implemented algorithms and discussing the results and the learned lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if f(x) >= 0 then y = face\n",
    "# else y = not face\n",
    "\n",
    "#f(x) = w1*phi(x) + w2*phi2(x) + ..\n",
    "# phi(x) = number of black pixels (example)\n",
    "\n",
    "# intialize weights randomonly at first\n",
    "\n",
    "# training condition is while less than 5 minutes or\n",
    "# the weights aren't changing from image to image\n",
    "\n",
    "#  update weights in training\n",
    " # if f(x) >=0 and y =face\n",
    " # or  f(x) <= 0 and y = not face\n",
    " # then do nothing\n",
    "\n",
    " # else if f(x) >= 0 and y = not face\n",
    " # then w1 = w1 -phi1 (x) \n",
    " #      w2 = w2 - phi2(x)\n",
    "\n",
    "# else if f(x) < 0 and y = face\n",
    " # then w1 = w1 + phi1 (x) \n",
    " #      w2 = w2 + phi2(x)\n",
    "\n",
    "\n",
    "#f = w1 * phi1(x) + w2 * phi2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nafri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\nafri\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/nafri/College/Senior Year/Spring Semester/Intro to AI/AI-FinalProject/Final Project/Berkeley_Example')\n",
    "sys.path.insert(1, 'C:/Users/jzlyn/OneDrive/Desktop/CS440/AI-FinalProject/Final Project/Berkeley_Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Berkeley_Example import samples\n",
    "from Berkeley_Example.perceptron import PerceptronClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(image,weights,over_estimate):\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            if over_estimate:\n",
    "                weights[i][j] -= image[i][j]\n",
    "            else:\n",
    "                weights[i][j] += image[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n,percent):\n",
    "    face_train_images = samples.loadDataFile('data/facedata/facedatatrain', n, 60, 70)\n",
    "    face_train_labels = samples.loadLabelsFile('data/facedata/facedatatrainlabels', n)\n",
    "    \n",
    "    size = n * percent\n",
    "\n",
    "    weights = np.random.uniform(-1, 1, size=(70, 60))\n",
    "    bias = np.random.uniform(-1, 1)\n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_train_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "            \n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "        if f[i] >= 0 and face_train_labels[rand_samples[i]] == 0:\n",
    "            update_weights(image,weights,True)\n",
    "            bias -= 1\n",
    "        elif f[i] < 0 and face_train_labels[rand_samples[i]] == 1:\n",
    "            update_weights(image,weights,False)\n",
    "            bias += 1\n",
    "\n",
    "    return (weights, bias)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(n,percent,weights,bias):\n",
    "    face_valid_images = samples.loadDataFile('data/facedata/facedatavalidation', n, 60, 70)\n",
    "    face_valid_labels = samples.loadLabelsFile('data/facedata/facedatavalidationlabels', n)\n",
    "\n",
    "    size = n * percent\n",
    " \n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_valid_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in range(len(f)):\n",
    "        if (f[i] >= 0 and face_valid_labels[rand_samples[i]] == 1) or (f[i] < 0 and face_valid_labels[rand_samples[i]] == 0):\n",
    "            num_correct += 1\n",
    "\n",
    "    result = num_correct / size\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Training Data Used = 10.00%\n",
      "[0.7641196013289037, 0.7308970099667774, 0.46511627906976744, 0.5980066445182723, 0.6644518272425249]\n",
      "Mean: 0.6445182724252492\n",
      "Std: 0.10631229235880399\n",
      "\n",
      "Percent of Training Data Used = 20.00%\n",
      "[0.6976744186046512, 0.6312292358803986, 0.6312292358803986, 0.7308970099667774, 0.6478405315614618]\n",
      "Mean: 0.6677740863787375\n",
      "Std: 0.039867109634551534\n",
      "\n",
      "Percent of Training Data Used = 30.00%\n",
      "[0.8084163898117386, 0.6976744186046511, 0.786267995570321, 0.7198228128460685, 0.7087486157253599]\n",
      "Mean: 0.7441860465116278\n",
      "Std: 0.0445177214667592\n",
      "\n",
      "Percent of Training Data Used = 40.00%\n",
      "[0.7059800664451827, 0.6312292358803986, 0.7973421926910299, 0.7142857142857143, 0.8388704318936877]\n",
      "Mean: 0.7375415282392026\n",
      "Std: 0.07305193829666455\n",
      "\n",
      "Percent of Training Data Used = 50.00%\n",
      "[0.8106312292358804, 0.8039867109634552, 0.8106312292358804, 0.7308970099667774, 0.7441860465116279]\n",
      "Mean: 0.7800664451827243\n",
      "Std: 0.035058886267835\n",
      "\n",
      "Percent of Training Data Used = 60.00%\n",
      "[0.813953488372093, 0.7308970099667774, 0.6866002214839424, 0.7862679955703211, 0.7641196013289037]\n",
      "Mean: 0.7563676633444074\n",
      "Std: 0.04424138284703916\n",
      "\n",
      "Percent of Training Data Used = 70.00%\n",
      "[0.7878500237304223, 0.8163265306122448, 0.7973421926910298, 0.8258186995728524, 0.8115804461319411]\n",
      "Mean: 0.8077835785476981\n",
      "Std: 0.013557529052762899\n",
      "\n",
      "Percent of Training Data Used = 80.00%\n",
      "[0.7890365448504983, 0.8347176079734219, 0.7433554817275747, 0.7267441860465116, 0.7558139534883721]\n",
      "Mean: 0.7699335548172758\n",
      "Std: 0.038296152436539874\n",
      "\n",
      "Percent of Training Data Used = 90.00%\n",
      "[0.8231819859726835, 0.8047249907715023, 0.830564784053156, 0.830564784053156, 0.7308970099667773]\n",
      "Mean: 0.803986710963455\n",
      "Std: 0.03774624741576734\n",
      "\n",
      "Percent of Training Data Used = 100.00%\n",
      "[0.867109634551495, 0.8471760797342193, 0.8305647840531561, 0.6644518272425249, 0.8338870431893688]\n",
      "Mean: 0.8086378737541529\n",
      "Std: 0.07322850004197236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 451\n",
    "VALID_SIZE = 301\n",
    "epochs = 5\n",
    "percentage = np.arange(0.1,1.1,.1)\n",
    "\n",
    "for percent in percentage:\n",
    "    accuracy = []\n",
    "    for i in range(epochs):\n",
    "        weights, bias = train(TRAIN_SIZE,percent) # return weights and bias used for validation\n",
    "        result = validate(VALID_SIZE,percent,weights,bias)\n",
    "        accuracy.append(result)\n",
    "        \n",
    "    print(f'Percent of Training Data Used = {\"{:.2%}\".format(percent)}')\n",
    "    print(accuracy)\n",
    "    print(f'Mean: {np.mean(accuracy)}')\n",
    "    print(f'Std: {np.std(accuracy)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = np.random.rand(1, 4200)\n",
    "phitures = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
