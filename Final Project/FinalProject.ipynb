{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement two classification algorithms for detecting faces and classifying digits:\n",
    "(a) Perceptron\n",
    "(b) Two-layer Neural Network (input layer, one hidden layer, output)\n",
    "2. Design the features for each of the two problems, and write a program for extracting the features from each image.\n",
    "You can also use the raw pixels directly as features (and avoid the process of designing features altogether) if that\n",
    "results in a better classification accuracy.\n",
    "3. Train the two algorithms on the part of the data set that is reserved for training. First, use only 10% of the data points\n",
    "that are reserved for training, then 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and finally 100%. All the results\n",
    "should a function of the number of data points used for training.\n",
    "4. Compare the performances of the two algorithms using the part of the data set that is reserved for testing, and report:\n",
    "• The time needed for training as a function of the number of data points used for training.\n",
    "• The prediction error (and standard deviation) as a function of the number of data points used for training.\n",
    "5. Write a report describing the implemented algorithms and discussing the results and the learned lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if f(x) >= 0 then y = face\n",
    "# else y = not face\n",
    "\n",
    "#f(x) = w1*phi(x) + w2*phi2(x) + ..\n",
    "# phi(x) = number of black pixels (example)\n",
    "\n",
    "# intialize weights randomonly at first\n",
    "\n",
    "# training condition is while less than 5 minutes or\n",
    "# the weights aren't changing from image to image\n",
    "\n",
    "#  update weights in training\n",
    " # if f(x) >=0 and y =face\n",
    " # or  f(x) <= 0 and y = not face\n",
    " # then do nothing\n",
    "\n",
    " # else if f(x) >= 0 and y = not face\n",
    " # then w1 = w1 -phi1 (x) \n",
    " #      w2 = w2 - phi2(x)\n",
    "\n",
    "# else if f(x) < 0 and y = face\n",
    " # then w1 = w1 + phi1 (x) \n",
    " #      w2 = w2 + phi2(x)\n",
    "\n",
    "\n",
    "#f = w1 * phi1(x) + w2 * phi2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine features - will need to obtain from image\n",
    "# First step is get data from facedatatrain to use in this notebook\n",
    "# Each face image is 70x60 (row x column) and each face begins and ends with an empty line (not including the 70x60).\n",
    "# Then make a feature matrix of size 70*60, where each pixel is a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nafri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\nafri\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/nafri/College/Senior Year/Spring Semester/Intro to AI/AI-FinalProject/Final Project/Berkeley_Example')\n",
    "sys.path.insert(1, 'C:/Users/jzlyn/OneDrive/Desktop/CS440/AI-FinalProject/Final Project/Berkeley_Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Berkeley_Example import samples\n",
    "from Berkeley_Example.perceptron import PerceptronClassifier\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    try:\n",
    "        sig =1/(1 + math.exp(-x))\n",
    "    except:\n",
    "        sig = 0   \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(image,weights,over_estimate):\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            if over_estimate:\n",
    "                weights[i][j] -= image[i][j]\n",
    "            else:\n",
    "                weights[i][j] += image[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_train(n,percent):\n",
    "    face_train_images = samples.loadDataFile('data/facedata/facedatatrain', n, 60, 70)\n",
    "    face_train_labels = samples.loadLabelsFile('data/facedata/facedatatrainlabels', n)\n",
    "    \n",
    "    size = n * percent\n",
    "\n",
    "    weights = np.random.uniform(-1, 1, size=(70, 60))\n",
    "    bias = np.random.uniform(-1, 1)\n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_train_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "            \n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "        if f[i] >= 0 and face_train_labels[rand_samples[i]] == 0:\n",
    "            update_weights(image,weights,True)\n",
    "            bias -= 1\n",
    "        elif f[i] < 0 and face_train_labels[rand_samples[i]] == 1:\n",
    "            update_weights(image,weights,False)\n",
    "            bias += 1\n",
    "\n",
    "    return (weights, bias)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_validate(n,percent,weights,bias):\n",
    "    face_valid_images = samples.loadDataFile('data/facedata/facedatavalidation', n, 60, 70)\n",
    "    face_valid_labels = samples.loadLabelsFile('data/facedata/facedatavalidationlabels', n)\n",
    "\n",
    "    size = n * percent\n",
    " \n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_valid_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in range(len(f)):\n",
    "        if (f[i] >= 0 and face_valid_labels[rand_samples[i]] == 1) or (f[i] < 0 and face_valid_labels[rand_samples[i]] == 0):\n",
    "            num_correct += 1\n",
    "\n",
    "    result = num_correct / size\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Training Data Used = 10.00%\n",
      "[0.4983388704318937, 0.6312292358803986, 0.7641196013289037, 0.7308970099667774, 0.4983388704318937]\n",
      "Mean: 0.6245847176079733\n",
      "Std: 0.11197541226812438\n",
      "\n",
      "Percent of Training Data Used = 20.00%\n",
      "[0.7475083056478405, 0.6146179401993355, 0.7308970099667774, 0.6976744186046512, 0.7641196013289037]\n",
      "Mean: 0.7109634551495015\n",
      "Std: 0.052948097842223374\n",
      "\n",
      "Percent of Training Data Used = 30.00%\n",
      "[0.6423034330011074, 0.7419712070874861, 0.6866002214839423, 0.7530454042081948, 0.7419712070874861]\n",
      "Mean: 0.7131782945736433\n",
      "Std: 0.042372373133353236\n",
      "\n",
      "Percent of Training Data Used = 40.00%\n",
      "[0.813953488372093, 0.7308970099667774, 0.8222591362126246, 0.7724252491694352, 0.8222591362126246]\n",
      "Mean: 0.792358803986711\n",
      "Std: 0.03585885904472243\n",
      "\n",
      "Percent of Training Data Used = 50.00%\n",
      "[0.6578073089700996, 0.6777408637873754, 0.7441860465116279, 0.8172757475083057, 0.7973421926910299]\n",
      "Mean: 0.7388704318936877\n",
      "Std: 0.06309144170349087\n",
      "\n",
      "Percent of Training Data Used = 60.00%\n",
      "[0.8084163898117387, 0.8416389811738649, 0.6201550387596899, 0.7862679955703211, 0.7142857142857143]\n",
      "Mean: 0.7541528239202657\n",
      "Std: 0.07896143286811025\n",
      "\n",
      "Percent of Training Data Used = 70.00%\n",
      "[0.8163265306122448, 0.7925961082107261, 0.8068343616516374, 0.7973421926910298, 0.8448030374940674]\n",
      "Mean: 0.811580446131941\n",
      "Std: 0.018503643749044084\n",
      "\n",
      "Percent of Training Data Used = 80.00%\n",
      "[0.8554817275747508, 0.8430232558139534, 0.8388704318936877, 0.8430232558139534, 0.8056478405315615]\n",
      "Mean: 0.8372093023255813\n",
      "Std: 0.016735416677416837\n",
      "\n",
      "Percent of Training Data Used = 90.00%\n",
      "[0.7530454042081948, 0.8121077888519748, 0.7530454042081948, 0.8268733850129197, 0.7936507936507935]\n",
      "Mean: 0.7877445551864155\n",
      "Std: 0.03022442154368212\n",
      "\n",
      "Percent of Training Data Used = 100.00%\n",
      "[0.8272425249169435, 0.8704318936877077, 0.7906976744186046, 0.770764119601329, 0.8073089700996677]\n",
      "Mean: 0.8132890365448505\n",
      "Std: 0.034101335336495266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 451\n",
    "VALID_SIZE = 301\n",
    "epochs = 5\n",
    "percentage = np.arange(0.1,1.1,.1)\n",
    "\n",
    "for percent in percentage:\n",
    "    accuracy = []\n",
    "    for i in range(epochs):\n",
    "        weights, bias = face_train(TRAIN_SIZE,percent) # return weights and bias used for validation\n",
    "        result = face_validate(VALID_SIZE,percent,weights,bias)\n",
    "        accuracy.append(result)\n",
    "\n",
    "    # Optional - Save to file later    \n",
    "    print(f'Percent of Training Data Used = {\"{:.2%}\".format(percent)}')\n",
    "    print(accuracy)\n",
    "    print(f'Mean: {np.mean(accuracy)}')\n",
    "    print(f'Std: {np.std(accuracy)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_digit(n,percent):\n",
    "    #np.random.seed(405)\n",
    "    # Read input from training digit file\n",
    "    images = samples.loadDataFile('data/digitdata/trainingimages', n, 28, 28)\n",
    "    labels = samples.loadLabelsFile('data/digitdata/traininglabels', n)\n",
    "\n",
    "    size = int(n * percent)\n",
    "    weights = np.random.randint(-5, 5, size=(10, 28, 28))\n",
    "    bias = np.random.randint(-5, 5, size=10)\n",
    "    \n",
    "    # Randomly select images based on size\n",
    "    rand_samples = np.random.choice(n, size, replace=False)\n",
    "\n",
    "    # List to all converted images\n",
    "    image_lst = []\n",
    "\n",
    "    # Convert image into integers\n",
    "    for i in rand_samples:\n",
    "        image = images[i].getPixels()\n",
    "        for r in range(28):\n",
    "            for c in range(28):\n",
    "               image[r][c] = samples.IntegerConversionFunction(image[r][c])\n",
    "        image_lst.append(image)\n",
    "\n",
    "    # Multiple iterations to make algo more accurate b/c there's so much data\n",
    "    for _ in range(5):\n",
    "        # Get predicted score for each digit\n",
    "        # Keep track of the digit with the highest score \n",
    "        for i in range(len(image_lst)):\n",
    "            image = image_lst[i]\n",
    "            predict = 0\n",
    "            max_predict = np.NINF\n",
    "            arg_max = 0\n",
    "            for d in range(10):\n",
    "                for r in range(28):\n",
    "                    for c in range(28):\n",
    "                        predict += weights[d][r][c] * image[r][c]\n",
    "                if predict > max_predict:\n",
    "                    arg_max = d\n",
    "                    max_predict = predict\n",
    "                    \n",
    "            # For digit with highest score, compare that to the actual score\n",
    "            # If not equal update weights \n",
    "            index = rand_samples[i]\n",
    "            if arg_max != labels[index]:\n",
    "                bias[arg_max] -= 1\n",
    "                bias[labels[index]] += 1\n",
    "                for r in range(28):\n",
    "                    for c in range(28):\n",
    "                        weights[arg_max][r][c] -= image[r][c]\n",
    "                        weights[labels[index]][r][c] += image[r][c]\n",
    "                \n",
    "    \n",
    "    return (weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_digit(n,percent,weights,bias):\n",
    "    # Read input from validation digit file\n",
    "    images = samples.loadDataFile('data/digitdata/validationimages', n, 28, 28)\n",
    "    labels = samples.loadLabelsFile('data/digitdata/validationlabels', n)\n",
    "\n",
    "    size = int(n * percent)\n",
    "\n",
    "    # Randomly select images based on size\n",
    "    rand_samples = np.random.choice(n, size, replace=False)\n",
    "\n",
    "    # List to all converted images\n",
    "    image_lst = []\n",
    "\n",
    "    # Convert image into integers\n",
    "    for i in rand_samples:\n",
    "        image = images[i].getPixels()\n",
    "        for r in range(28):\n",
    "            for c in range(28):\n",
    "               image[r][c] = samples.IntegerConversionFunction(image[r][c])\n",
    "        image_lst.append(image)\n",
    "\n",
    "    correct_predicts = 0\n",
    "    # Don't need to iterate 5 times, not training so just let validation run\n",
    "    for i in range(len(image_lst)):\n",
    "        image = image_lst[i]\n",
    "        predict = 0\n",
    "        max_predict = np.NINF\n",
    "        arg_max = 0\n",
    "        for d in range(10):\n",
    "            for r in range(28):\n",
    "                for c in range(28):\n",
    "                    predict += weights[d][r][c] * image[r][c]\n",
    "            if predict > max_predict:\n",
    "                arg_max = d\n",
    "                max_predict = predict\n",
    "                \n",
    "        index = rand_samples[i]\n",
    "        if arg_max == labels[index]:\n",
    "            correct_predicts += 1\n",
    "    \n",
    "    return correct_predicts / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Training Data Used = 100.00%\n",
      "[0.832, 0.786, 0.828, 0.819, 0.822]\n",
      "Mean: 0.8173999999999999\n",
      "Std: 0.01634135857265237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 5000\n",
    "VALID_SIZE = 1000\n",
    "epochs = 5\n",
    "\n",
    "percent = 1\n",
    "accuracy = []\n",
    "for i in range(epochs):\n",
    "    weights, bias = train_digit(TRAIN_SIZE,percent) # return weights and bias used for validation\n",
    "    result = validate_digit(VALID_SIZE,percent,weights,bias)\n",
    "    accuracy.append(result)\n",
    "\n",
    "# Optional - Save to file later    \n",
    "print(f'Percent of Training Data Used = {\"{:.2%}\".format(percent)}')\n",
    "print(accuracy)\n",
    "print(f'Mean: {np.mean(accuracy)}')\n",
    "print(f'Std: {np.std(accuracy)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imag = 10\n",
    "conv_imag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_train_imgs = samples.loadDataFile('data/facedata/facedatatrain', num_imag, 60, 70)\n",
    "face_train_labs = samples.loadLabelsFile('data/facedata/facedatatrainlabels', num_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_imag):\n",
    "    matrix = face_train_imgs[i].getPixels()\n",
    "    for r in range(len(matrix)):\n",
    "        for c in range(len(matrix[0])):\n",
    "            matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "    conv_imag.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you're using NumPy\n",
    "W1 = np.random.randn(1800, 4200) * np.sqrt(2.0 / (4200 + 1800))\n",
    "b1 = np.zeros(1800)\n",
    "W2 = np.random.randn(1, 1800) * np.sqrt(2.0 / (1800 + 1))\n",
    "b2 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(W1)\n",
    "# print(W1.shape)\n",
    "#img1 =conv_imag[0]\n",
    "for image in conv_imag:\n",
    "  flatImg1 = [element for row in image for element in row] # create function to flatten\n",
    "  flatImg1 =np.array(flatImg1)\n",
    "  print(flatImg1.shape)\n",
    "  print(W1[0,:].shape)\n",
    "  # for hidNode in range(W1.shape[0]): # 1800 # for each row in W1, use the W1 weights multiple by pixels and sum for that node\n",
    "  #   z1 = np.dot(flatImg1, W1[hidNode,:]) + b1[hidNode]\n",
    "  #   #print(z1)\n",
    "  #   #print(W1[hidNode,:])\n",
    "  z1 = np.array([np.dot(flatImg1, W1[hidNode,:]) + b1[hidNode] for hidNode in range(W1.shape[0])])\n",
    "  print(z1)\n",
    "  print(z1.shape)\n",
    "  a1 =np.array(list(map(sigmoid,z1)))\n",
    "  print(a1)\n",
    "  z2 = (np.dot(a1, W2.T) + b2)[0]\n",
    "  print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "    # Input to hidden layer\n",
    "    z1 = np.dot(X, W1.T) + b1 # one value\n",
    "    a1 = np.maximum(0, z1)  # ReLU activation\n",
    "\n",
    "    # Hidden to output layer\n",
    "    z2 = np.dot(a1, W2.T) + b2\n",
    "    output = 1 / (1 + np.exp(-z2))  # Sigmoid activation\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_train_images = samples.loadDataFile('data/facedata/facedatatrain', n, 60, 70)\n",
    "face_train_labels = samples.loadLabelsFile('data/facedata/facedatatrainlabels', n)\n",
    "\n",
    "size = n * percent\n",
    "\n",
    "weights = np.random.uniform(-1, 1, size=(70, 60))\n",
    "bias = np.random.uniform(-1, 1)\n",
    "f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "image_lst = []\n",
    "\n",
    "rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "\n",
    "for i in rand_samples:\n",
    "    matrix = face_train_images[i].getPixels()\n",
    "    for r in range(len(matrix)):\n",
    "        for c in range(len(matrix[0])):\n",
    "            matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "    image_lst.append(matrix)\n",
    "    \n",
    "for i in range(len(image_lst)):\n",
    "    f[i] = bias\n",
    "    image = image_lst[i]\n",
    "    for r in range(len(image)):\n",
    "        for c in range(len(image[0])):\n",
    "            f[i] += weights[r][c] * image[r][c]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
