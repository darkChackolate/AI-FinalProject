{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement two classification algorithms for detecting faces and classifying digits:\n",
    "(a) Perceptron\n",
    "(b) Two-layer Neural Network (input layer, one hidden layer, output)\n",
    "2. Design the features for each of the two problems, and write a program for extracting the features from each image.\n",
    "You can also use the raw pixels directly as features (and avoid the process of designing features altogether) if that\n",
    "results in a better classification accuracy.\n",
    "3. Train the two algorithms on the part of the data set that is reserved for training. First, use only 10% of the data points\n",
    "that are reserved for training, then 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, and finally 100%. All the results\n",
    "should a function of the number of data points used for training.\n",
    "4. Compare the performances of the two algorithms using the part of the data set that is reserved for testing, and report:\n",
    "• The time needed for training as a function of the number of data points used for training.\n",
    "• The prediction error (and standard deviation) as a function of the number of data points used for training.\n",
    "5. Write a report describing the implemented algorithms and discussing the results and the learned lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if f(x) >= 0 then y = face\n",
    "# else y = not face\n",
    "\n",
    "#f(x) = w1*phi(x) + w2*phi2(x) + ..\n",
    "# phi(x) = number of black pixels (example)\n",
    "\n",
    "# intialize weights randomonly at first\n",
    "\n",
    "# training condition is while less than 5 minutes or\n",
    "# the weights aren't changing from image to image\n",
    "\n",
    "#  update weights in training\n",
    " # if f(x) >=0 and y =face\n",
    " # or  f(x) <= 0 and y = not face\n",
    " # then do nothing\n",
    "\n",
    " # else if f(x) >= 0 and y = not face\n",
    " # then w1 = w1 -phi1 (x) \n",
    " #      w2 = w2 - phi2(x)\n",
    "\n",
    "# else if f(x) < 0 and y = face\n",
    " # then w1 = w1 + phi1 (x) \n",
    " #      w2 = w2 + phi2(x)\n",
    "\n",
    "\n",
    "#f = w1 * phi1(x) + w2 * phi2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine features - will need to obtain from image\n",
    "# First step is get data from facedatatrain to use in this notebook\n",
    "# Each face image is 70x60 (row x column) and each face begins and ends with an empty line (not including the 70x60).\n",
    "# Then make a feature matrix of size 70*60, where each pixel is a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nafri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\nafri\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/nafri/College/Senior Year/Spring Semester/Intro to AI/AI-FinalProject/Final Project/Berkeley_Example')\n",
    "sys.path.insert(1, 'C:/Users/jzlyn/OneDrive/Desktop/CS440/AI-FinalProject/Final Project/Berkeley_Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Berkeley_Example import samples\n",
    "from Berkeley_Example.perceptron import PerceptronClassifier\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    try:\n",
    "        sig =1/(1 + math.exp(-x))\n",
    "    except:\n",
    "        sig = 0   \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(image,weights,over_estimate):\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            if over_estimate:\n",
    "                weights[i][j] -= image[i][j]\n",
    "            else:\n",
    "                weights[i][j] += image[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_train(n,percent):\n",
    "    face_train_images = samples.loadDataFile('data/facedata/facedatatrain', n, 60, 70)\n",
    "    face_train_labels = samples.loadLabelsFile('data/facedata/facedatatrainlabels', n)\n",
    "    \n",
    "    size = n * percent\n",
    "\n",
    "    weights = np.random.uniform(-1, 1, size=(70, 60))\n",
    "    bias = np.random.uniform(-1, 1)\n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_train_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "            \n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "        if f[i] >= 0 and face_train_labels[rand_samples[i]] == 0:\n",
    "            update_weights(image,weights,True)\n",
    "            bias -= 1\n",
    "        elif f[i] < 0 and face_train_labels[rand_samples[i]] == 1:\n",
    "            update_weights(image,weights,False)\n",
    "            bias += 1\n",
    "\n",
    "    return (weights, bias)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_validate(n,percent,weights,bias):\n",
    "    face_valid_images = samples.loadDataFile('data/facedata/facedatavalidation', n, 60, 70)\n",
    "    face_valid_labels = samples.loadLabelsFile('data/facedata/facedatavalidationlabels', n)\n",
    "\n",
    "    size = n * percent\n",
    " \n",
    "    f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = face_valid_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        f[i] = bias\n",
    "        image = image_lst[i]\n",
    "        for r in range(len(image)):\n",
    "            for c in range(len(image[0])):\n",
    "                f[i] += weights[r][c] * image[r][c]\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in range(len(f)):\n",
    "        if (f[i] >= 0 and face_valid_labels[rand_samples[i]] == 1) or (f[i] < 0 and face_valid_labels[rand_samples[i]] == 0):\n",
    "            num_correct += 1\n",
    "\n",
    "    result = num_correct / size\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Training Data Used = 10.00%\n",
      "[0.8637873754152824, 0.7641196013289037, 0.5315614617940199, 0.5647840531561461, 0.5980066445182723]\n",
      "Mean: 0.6644518272425249\n",
      "Std: 0.12780986087489268\n",
      "\n",
      "Percent of Training Data Used = 20.00%\n",
      "[0.6810631229235881, 0.7973421926910299, 0.6810631229235881, 0.6976744186046512, 0.6976744186046512]\n",
      "Mean: 0.7109634551495017\n",
      "Std: 0.04382360783479375\n",
      "\n",
      "Percent of Training Data Used = 30.00%\n",
      "[0.7973421926910298, 0.8416389811738648, 0.830564784053156, 0.6423034330011074, 0.6866002214839423]\n",
      "Mean: 0.7596899224806201\n",
      "Std: 0.08034709699763921\n",
      "\n",
      "Percent of Training Data Used = 40.00%\n",
      "[0.7807308970099668, 0.7308970099667774, 0.8056478405315615, 0.8637873754152824, 0.7641196013289037]\n",
      "Mean: 0.7890365448504982\n",
      "Std: 0.04457278360464697\n",
      "\n",
      "Percent of Training Data Used = 50.00%\n",
      "[0.7973421926910299, 0.7308970099667774, 0.8305647840531561, 0.717607973421927, 0.7906976744186046]\n",
      "Mean: 0.7734219269102991\n",
      "Std: 0.04256642492504176\n",
      "\n",
      "Percent of Training Data Used = 60.00%\n",
      "[0.813953488372093, 0.7530454042081949, 0.7530454042081949, 0.7918050941306756, 0.8471760797342193]\n",
      "Mean: 0.7918050941306756\n",
      "Std: 0.03622464503609331\n",
      "\n",
      "Percent of Training Data Used = 70.00%\n",
      "[0.7783578547698149, 0.8400569530137636, 0.830564784053156, 0.8020882771713336, 0.8922638822971048]\n",
      "Mean: 0.8286663502610345\n",
      "Std: 0.038510608021074116\n",
      "\n",
      "Percent of Training Data Used = 80.00%\n",
      "[0.7973421926910299, 0.8637873754152824, 0.7308970099667774, 0.851328903654485, 0.8388704318936877]\n",
      "Mean: 0.8164451827242525\n",
      "Std: 0.048258601482837025\n",
      "\n",
      "Percent of Training Data Used = 90.00%\n",
      "[0.8490217792543373, 0.7493540051679586, 0.8490217792543373, 0.7198228128460685, 0.8047249907715023]\n",
      "Mean: 0.7943890734588408\n",
      "Std: 0.05227730075186558\n",
      "\n",
      "Percent of Training Data Used = 100.00%\n",
      "[0.6877076411960132, 0.840531561461794, 0.8438538205980066, 0.7906976744186046, 0.8504983388704319]\n",
      "Mean: 0.8026578073089701\n",
      "Std: 0.061281048771661566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 451\n",
    "VALID_SIZE = 301\n",
    "epochs = 5\n",
    "percentage = np.arange(0.1,1.1,.1)\n",
    "\n",
    "for percent in percentage:\n",
    "    accuracy = []\n",
    "    for i in range(epochs):\n",
    "        weights, bias = face_train(TRAIN_SIZE,percent) # return weights and bias used for validation\n",
    "        result = face_validate(VALID_SIZE,percent,weights,bias)\n",
    "        accuracy.append(result)\n",
    "\n",
    "    # Optional - Save to file later    \n",
    "    print(f'Percent of Training Data Used = {\"{:.2%}\".format(percent)}')\n",
    "    print(accuracy)\n",
    "    print(f'Mean: {np.mean(accuracy)}')\n",
    "    print(f'Std: {np.std(accuracy)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_digit_weights(image,weights,bias,prediction,actual):\n",
    "    bias[prediction] -= 1\n",
    "    bias[actual] += 1\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            weights[prediction][i][j] -= image[i][j]\n",
    "            weights[actual][i][j] += image[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_train(n,percent):\n",
    "    digit_train_images = samples.loadDataFile('data/digitdata/trainingimages', n, 28, 28)\n",
    "    digit_train_labels = samples.loadLabelsFile('data/digitdata/traininglabels', n)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(5):\n",
    "    \n",
    "    size = n * percent\n",
    "    DIGITS = 10\n",
    "    weights = np.random.randint(-400, 400, size=(DIGITS, 28, 28))\n",
    "    #weights = np.random.randint(-5, 5, size=(DIGITS, 28, 28))\n",
    "    #print(weights)\n",
    "    bias = np.random.randint(-200, 200, size=DIGITS)\n",
    "    #bias = np.random.randint(-5, 5, size=DIGITS)\n",
    "    #print(bias)\n",
    "    #f = np.zeros(int(size)).astype(float)\n",
    "    prediction = 0\n",
    "    #print(f)\n",
    "    accuracy = []\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, size, replace=False)\n",
    "    #rand_samples = [0,1,2,3,4]\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = digit_train_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        #print(matrix)\n",
    "        image_lst.append(matrix)\n",
    "\n",
    "    #print(rand_samples)\n",
    "            \n",
    "\n",
    "    for i in range(len(image_lst)):\n",
    "        max_predict = np.NINF\n",
    "        arg_max = 0\n",
    "        prediction = 0\n",
    "        for d in range(0,10):\n",
    "            #f[i] = bias[d]\n",
    "            #prediction = bias[d]\n",
    "            image = image_lst[i]\n",
    "            for r in range(len(image)):\n",
    "                for c in range(len(image[0])):\n",
    "                    prediction += weights[d][r][c] * image[r][c]\n",
    "            #print(f'f digit {d} image {i}: {f[d][i]}')\n",
    "            prediction += bias[d]\n",
    "            if prediction > max_predict:\n",
    "                max_predict = prediction\n",
    "                arg_max = d\n",
    "        \n",
    "        #print(f'Predicted Digit: {arg_max} Actual Digit: {digit_train_labels[rand_samples[i]]}')\n",
    "        #print()\n",
    "\n",
    "        if arg_max == digit_train_labels[rand_samples[i]]:\n",
    "            accuracy.append(1)\n",
    "        else:\n",
    "            accuracy.append(0)\n",
    "\n",
    "        if arg_max != digit_train_labels[rand_samples[i]]:\n",
    "            #print(f'Before update: Bias Predict = {bias[arg_max]} Bias Actual = {bias[digit_train_labels[rand_samples[i]]]}')\n",
    "            update_digit_weights(image,weights,bias,arg_max,digit_train_labels[rand_samples[i]])\n",
    "            #print(f'After update: Bias Predict = {bias[arg_max]} Bias Actual = {bias[digit_train_labels[rand_samples[i]]]}')\n",
    "\n",
    "    print(np.mean(accuracy))\n",
    "\n",
    "        \n",
    "\n",
    "    return (weights, bias)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 305, -123,  342, ..., -298,   28,  118],\n",
       "         [-132,  -62, -280, ...,  -40,  272, -149],\n",
       "         [-293,  339,   20, ...,  -79,  111, -359],\n",
       "         ...,\n",
       "         [ 275, -133,  -37, ...,  384,  389,  -60],\n",
       "         [-398,   40, -329, ...,  124, -240, -201],\n",
       "         [  38,   73, -130, ...,  -31,  224,  395]],\n",
       " \n",
       "        [[ 272, -390,  244, ...,  304,  309,   92],\n",
       "         [ 311,   57,  187, ...,  -67,    6,  -53],\n",
       "         [ 284, -377,  260, ...,  235,   86,  330],\n",
       "         ...,\n",
       "         [ 262, -119,  -72, ..., -251, -247,  128],\n",
       "         [-390, -252, -202, ...,   66, -316,  -40],\n",
       "         [-327, -242, -392, ...,  362,  164, -259]],\n",
       " \n",
       "        [[-281, -118,    7, ...,   23, -116,   26],\n",
       "         [ -74,  148, -328, ..., -206, -302,  -12],\n",
       "         [ 107, -207,  334, ..., -376, -131,  347],\n",
       "         ...,\n",
       "         [-390, -151, -399, ...,  248,   26,  180],\n",
       "         [ 395,  149, -172, ...,  -25, -292,  107],\n",
       "         [-297,  310, -315, ...,  -72, -197,   76]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 314,  133, -132, ...,  -44,  359,    7],\n",
       "         [-236,  -67,   34, ...,   91,  101,   30],\n",
       "         [-195, -390, -193, ...,  -73,  238,  -53],\n",
       "         ...,\n",
       "         [-217, -129,  341, ...,   79, -253,  -18],\n",
       "         [  48,   86, -236, ...,  -77, -194,  387],\n",
       "         [ -74,  -44, -310, ...,  165, -318, -311]],\n",
       " \n",
       "        [[ -56, -173,   99, ...,  345, -299,   -1],\n",
       "         [ 103,  -73,  202, ..., -288, -225, -146],\n",
       "         [-295, -232,  367, ...,   26,  -71,  313],\n",
       "         ...,\n",
       "         [-321, -115,  178, ...,  249,  -63,  210],\n",
       "         [   7,  194, -307, ..., -233,  122,   93],\n",
       "         [ 158,  389, -316, ...,   49,  186,  372]],\n",
       " \n",
       "        [[-339, -272,   -6, ..., -338, -243, -155],\n",
       "         [ 290,  253, -358, ..., -357, -126,  140],\n",
       "         [ -67,  170, -355, ...,  276, -203,   85],\n",
       "         ...,\n",
       "         [ 361,   28,  362, ..., -100, -268,  -75],\n",
       "         [ -19, -260, -384, ...,   93,   21,  212],\n",
       "         [ 106, -220, -324, ..., -179, -200,  379]]]),\n",
       " array([-242,  239, -288,  133,  286, -180,  -26,   60,  -90, -148]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_train(5000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_validate(n,percent,weights,bias):\n",
    "    digit_valid_images = samples.loadDataFile('data/digitdata/validationimages', n, 28, 28)\n",
    "    digit_valid_labels = samples.loadLabelsFile('data/digitdata/validationlabels', n)\n",
    "\n",
    "    size = n * percent\n",
    "    #print(size)\n",
    "    DIGITS = 10\n",
    " \n",
    "    #f = np.zeros(int(size)).astype(float)\n",
    "    #print(f)\n",
    "    prediction = 0\n",
    "\n",
    "    image_lst = []\n",
    "\n",
    "    rand_samples = np.random.choice(n, size, replace=False)\n",
    "    \n",
    "    for i in rand_samples:\n",
    "        matrix = digit_valid_images[i].getPixels()\n",
    "        for r in range(len(matrix)):\n",
    "            for c in range(len(matrix[0])):\n",
    "                matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "        image_lst.append(matrix)\n",
    "        \n",
    "    accuracy = []\n",
    "    #prediction = []\n",
    "    for i in range(len(image_lst)):\n",
    "        max_predict = np.NINF\n",
    "        arg_max = 0 \n",
    "        prediction = 0\n",
    "        for d in range(DIGITS):\n",
    "            #f[i] = bias[d]\n",
    "            #prediction = bias[d]\n",
    "            image = image_lst[i]\n",
    "            for r in range(len(image)):\n",
    "                for c in range(len(image[0])):\n",
    "                    #f[i] += weights[d][r][c] * image[r][c]\n",
    "                    prediction += weights[d][r][c] * image[r][c]\n",
    "            #print(f'f digit {d} image {i}: {f[i]}')\n",
    "            prediction += bias[d]\n",
    "            if prediction > max_predict:\n",
    "                max_predict = prediction\n",
    "                arg_max = d\n",
    "\n",
    "        if arg_max == digit_valid_labels[rand_samples[i]]:\n",
    "            accuracy.append(1)\n",
    "        else:\n",
    "            accuracy.append(0)\n",
    "            \n",
    "\n",
    "        #print()\n",
    "            \n",
    "        #prediction.append(arg_max)\n",
    "\n",
    "    '''\n",
    "    num_correct = 0\n",
    "    for i in range(len(prediction)):\n",
    "        #print(f'Predicted Digit: {prediction[i]} Actual Digit: {digit_valid_labels[rand_samples[i]]}')\n",
    "        if prediction[i] == digit_valid_labels[rand_samples[i]]:\n",
    "            num_correct += 1\n",
    "\n",
    "    result = num_correct / size\n",
    "    '''\n",
    "\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Training Data Used = 100.00%\n",
      "[0.447]\n",
      "Mean: 0.447\n",
      "Std: 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 9\u001b[0m     weights, bias \u001b[38;5;241m=\u001b[39m \u001b[43mdigit_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpercent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# return weights and bias used for validation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     result \u001b[38;5;241m=\u001b[39m digit_validate(VALID_SIZE,percent,weights,bias)\n\u001b[0;32m     11\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[77], line 42\u001b[0m, in \u001b[0;36mdigit_train\u001b[1;34m(n, percent)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(image)):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(image[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m---> 42\u001b[0m         prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[d][r][c] \u001b[38;5;241m*\u001b[39m image[r][c]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#print(f'f digit {d} image {i}: {f[d][i]}')\u001b[39;00m\n\u001b[0;32m     44\u001b[0m prediction \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bias[d]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 5000\n",
    "VALID_SIZE = 1000\n",
    "epochs = 5\n",
    "#percentage = [1] #np.arange(0.1,1.1,.1)\n",
    "percent = 1\n",
    "#for percent in percentage:\n",
    "accuracy = []\n",
    "for i in range(epochs):\n",
    "    weights, bias = digit_train(TRAIN_SIZE,percent) # return weights and bias used for validation\n",
    "    result = digit_validate(VALID_SIZE,percent,weights,bias)\n",
    "    accuracy.append(result)\n",
    "\n",
    "    # Optional - Save to file later    \n",
    "    print(f'Percent of Training Data Used = {\"{:.2%}\".format(percent)}')\n",
    "    print(accuracy)\n",
    "    print(f'Mean: {np.mean(accuracy)}')\n",
    "    print(f'Std: {np.std(accuracy)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imag = 10\n",
    "conv_imag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_train_imgs = samples.loadDataFile('data/facedata/facedatatrain', num_imag, 60, 70)\n",
    "face_train_labs = samples.loadLabelsFile('data/facedata/facedatatrainlabels', num_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_imag):\n",
    "    matrix = face_train_imgs[i].getPixels()\n",
    "    for r in range(len(matrix)):\n",
    "        for c in range(len(matrix[0])):\n",
    "            matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "    conv_imag.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you're using NumPy\n",
    "W1 = np.random.randn(1800, 4200) * np.sqrt(2.0 / (4200 + 1800))\n",
    "b1 = np.zeros(1800)\n",
    "W2 = np.random.randn(1, 1800) * np.sqrt(2.0 / (1800 + 1))\n",
    "b2 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200,)\n",
      "(4200,)\n",
      "[-0.84725431  1.44218088 -1.90188063 ...  0.06361933 -0.11833534\n",
      "  0.61138067]\n",
      "(1800,)\n",
      "[0.30000915 0.80879215 0.12989577 ... 0.51589947 0.47045064 0.64825569]\n",
      "-1.3935079136918014\n",
      "(4200,)\n",
      "(4200,)\n",
      "[-0.34567203 -0.77415315 -2.77890341 ... -0.31941691 -1.03682656\n",
      " -1.51605465]\n",
      "(1800,)\n",
      "[0.41443233 0.31558138 0.0584749  ... 0.42081786 0.26176277 0.18004323]\n",
      "-0.7074811552802782\n",
      "(4200,)\n",
      "(4200,)\n",
      "[ 0.34882333 -0.57024467  0.99396325 ...  0.66683942 -0.60539098\n",
      " -2.14884812]\n",
      "(1800,)\n",
      "[0.58633221 0.36118037 0.72987003 ... 0.66079509 0.35311129 0.10443891]\n",
      "-0.6175436282224237\n",
      "(4200,)\n",
      "(4200,)\n",
      "[-0.09917258  0.87731834 -1.06307375 ...  1.0508588  -0.00275999\n",
      " -0.5411449 ]\n",
      "(1800,)\n",
      "[0.47522715 0.70626621 0.2567225  ... 0.74093978 0.49931    0.36792129]\n",
      "-0.42042310541194045\n",
      "(4200,)\n",
      "(4200,)\n",
      "[ 0.34175467 -0.11665319  0.20654492 ... -0.07147699 -0.25908227\n",
      " -1.05524715]\n",
      "(1800,)\n",
      "[0.58461669 0.47086973 0.55145344 ... 0.48213836 0.43558932 0.25821878]\n",
      "-0.6943467502524342\n",
      "(4200,)\n",
      "(4200,)\n",
      "[ 1.47382504 -0.23877298 -1.14273114 ... -0.80070806  0.61961306\n",
      "  0.09875369]\n",
      "(1800,)\n",
      "[0.81363808 0.44058875 0.24181927 ... 0.30987408 0.65013054 0.52466838]\n",
      "-1.1528185038863905\n",
      "(4200,)\n",
      "(4200,)\n",
      "[-0.89625564 -0.32631846 -1.30405479 ... -1.03721641 -1.36034079\n",
      " -0.46688894]\n",
      "(1800,)\n",
      "[0.28982057 0.41913667 0.21348339 ... 0.26168745 0.20418492 0.38535285]\n",
      "-0.7258760257045895\n",
      "(4200,)\n",
      "(4200,)\n",
      "[ 0.4393538  -0.15685299 -1.21395477 ...  0.82617396 -1.56050288\n",
      " -0.128524  ]\n",
      "(1800,)\n",
      "[0.60810504 0.46086695 0.22900205 ... 0.69554533 0.1735745  0.46791316]\n",
      "-0.9352039209078762\n",
      "(4200,)\n",
      "(4200,)\n",
      "[-0.23854558  0.86276798 -0.99805826 ...  1.9835657   0.93684749\n",
      "  1.34709969]\n",
      "(1800,)\n",
      "[0.4406448  0.70323864 0.26932336 ... 0.87906075 0.71846242 0.79365506]\n",
      "-1.235004299514627\n",
      "(4200,)\n",
      "(4200,)\n",
      "[ 3.88746214e-01 -1.02822920e-03  4.67376711e-01 ... -4.64542472e-01\n",
      " -1.20273781e+00  2.33349200e-02]\n",
      "(1800,)\n",
      "[0.59598084 0.49974294 0.61476267 ... 0.38590878 0.23098853 0.50583347]\n",
      "-0.5959068037515416\n"
     ]
    }
   ],
   "source": [
    "# print(W1)\n",
    "# print(W1.shape)\n",
    "#img1 =conv_imag[0]\n",
    "for image in conv_imag:\n",
    "  flatImg1 = [element for row in image for element in row] # create function to flatten\n",
    "  flatImg1 =np.array(flatImg1)\n",
    "  print(flatImg1.shape)\n",
    "  print(W1[0,:].shape)\n",
    "  # for hidNode in range(W1.shape[0]): # 1800 # for each row in W1, use the W1 weights multiple by pixels and sum for that node\n",
    "  #   z1 = np.dot(flatImg1, W1[hidNode,:]) + b1[hidNode]\n",
    "  #   #print(z1)\n",
    "  #   #print(W1[hidNode,:])\n",
    "  z1 = np.array([np.dot(flatImg1, W1[hidNode,:]) + b1[hidNode] for hidNode in range(W1.shape[0])])\n",
    "  print(z1)\n",
    "  print(z1.shape)\n",
    "  a1 =np.array(list(map(sigmoid,z1)))\n",
    "  print(a1)\n",
    "  z2 = (np.dot(a1, W2.T) + b2)[0]\n",
    "  print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "    # Input to hidden layer\n",
    "    z1 = np.dot(X, W1.T) + b1 # one value\n",
    "    a1 = np.maximum(0, z1)  # ReLU activation\n",
    "\n",
    "    # Hidden to output layer\n",
    "    z2 = np.dot(a1, W2.T) + b2\n",
    "    output = 1 / (1 + np.exp(-z2))  # Sigmoid activation\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m face_train_images \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mloadDataFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/facedata/facedatatrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mn\u001b[49m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m      2\u001b[0m face_train_labels \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mloadLabelsFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/facedata/facedatatrainlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, n)\n\u001b[0;32m      4\u001b[0m size \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m*\u001b[39m percent\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "face_train_images = samples.loadDataFile('data/facedata/facedatatrain', n, 60, 70)\n",
    "face_train_labels = samples.loadLabelsFile('data/facedata/facedatatrainlabels', n)\n",
    "\n",
    "size = n * percent\n",
    "\n",
    "weights = np.random.uniform(-1, 1, size=(70, 60))\n",
    "bias = np.random.uniform(-1, 1)\n",
    "f = np.zeros(int(size)).astype(float)\n",
    "\n",
    "image_lst = []\n",
    "\n",
    "rand_samples = np.random.choice(n, int(size), replace=False)\n",
    "\n",
    "for i in rand_samples:\n",
    "    matrix = face_train_images[i].getPixels()\n",
    "    for r in range(len(matrix)):\n",
    "        for c in range(len(matrix[0])):\n",
    "            matrix[r][c] = samples.IntegerConversionFunction(matrix[r][c])\n",
    "    image_lst.append(matrix)\n",
    "    \n",
    "for i in range(len(image_lst)):\n",
    "    f[i] = bias\n",
    "    image = image_lst[i]\n",
    "    for r in range(len(image)):\n",
    "        for c in range(len(image[0])):\n",
    "            f[i] += weights[r][c] * image[r][c]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
